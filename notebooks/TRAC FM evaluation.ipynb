{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pld_rq1XtZbd"
   },
   "source": [
    "## Decode and translate TRAC FM voice poll samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDEFy_3U0OB3"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentencepiece\n",
    "!pip install -q datasets\n",
    "!pip install -q transformers\n",
    "!pip install -q librosa\n",
    "!pip install -q soundfile\n",
    "!git clone https://github.com/sunbirdai/salt.git\n",
    "!pip install -qr salt/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThhtZdrE00cJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "import librosa\n",
    "from IPython import display\n",
    "import huggingface_hub\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import salt.utils\n",
    "import string\n",
    "import pandas as pd\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "# Suppress some non-informative warnings from Transformers\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hq_QUsoDPAW7"
   },
   "outputs": [],
   "source": [
    "huggingface_hub.notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXrmiussPAW8"
   },
   "outputs": [],
   "source": [
    "model_path = 'jq/whisper-large-v3-salt'\n",
    "processor = transformers.WhisperProcessor.from_pretrained(\n",
    "    model_path, language=None, task=\"transcribe\")\n",
    "asr_model = transformers.WhisperForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_tokenizer = transformers.NllbTokenizer.from_pretrained(\n",
    "    \"facebook/nllb-200-distilled-1.3B\")\n",
    "translation_model = transformers.M2M100ForConditionalGeneration.from_pretrained(\n",
    "    'jq/nllb-1.3B-many-to-many-pronouncorrection-charaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6IdhCg22ay-"
   },
   "outputs": [],
   "source": [
    "whisper_pipeline = transformers.pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model = asr_model,\n",
    "    tokenizer = processor.tokenizer,\n",
    "    feature_extractor = processor.feature_extractor,\n",
    "    device = 'cuda:0',\n",
    "    torch_dtype=torch.float16,\n",
    "    model_kwargs=({\"attn_implementation\": \n",
    "        \"flash_attention_2\" if transformers.utils.is_flash_attn_2_available()\n",
    "        else \"sdpa\"}\n",
    "    ),\n",
    "    generate_kwargs = {\n",
    "        \"language\": None,\n",
    "        \"forced_decoder_ids\": None,\n",
    "        \"repetition_penalty\": 1.0,\n",
    "        \"no_repeat_ngram_size\": 4,\n",
    "        \"num_beams\": 3,\n",
    "    },\n",
    "    chunk_length_s = 30,\n",
    "    batch_size = 1, # Higher = faster on long audio but more GPU memory usage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(text, source_language, target_language):\n",
    "  _language_codes = {\n",
    "      'eng': 256047,\n",
    "      'ach': 256111,\n",
    "      'lgg': 256008,\n",
    "      'lug': 256110,\n",
    "      'nyn': 256002,\n",
    "      'teo': 256006,\n",
    "  }\n",
    "\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  inputs = translation_tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "  inputs['input_ids'][0][0] = _language_codes[source_language]\n",
    "  translated_tokens = translation_model.to(device).generate(\n",
    "      **inputs,\n",
    "      forced_bos_token_id=_language_codes[target_language],\n",
    "      max_length=100,\n",
    "      num_beams=5,\n",
    "      repetition_penalty=1.1,\n",
    "  )\n",
    "\n",
    "  result = translation_tokenizer.batch_decode(\n",
    "      translated_tokens, skip_special_tokens=True)[0]\n",
    "  return result\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'[.?!]', text)\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    return sentences\n",
    "\n",
    "def maybe_add_full_stop(s):\n",
    "    if len(s):\n",
    "        if s[-1] not in string.punctuation:\n",
    "            s = s + '.'\n",
    "        return s\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def translate_sentences(text, source_language, target_language):\n",
    "    sentences = split_into_sentences(text)\n",
    "    translated_sentences = [\n",
    "        translate_sentence(s, source_language, target_language) for s in sentences]\n",
    "    translated_sentences = [\n",
    "        maybe_add_full_stop(s) for s in translated_sentences]\n",
    "    return ' '.join(translated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "VH1xLxdQXSML",
    "outputId": "0c1c811b-5c5b-4531-d183-f65551dda18a"
   },
   "outputs": [],
   "source": [
    "test_dataset = datasets.load_dataset(\n",
    "    \"Sunbird/salt-practical-eval\", 'trac_fm_lug', split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do speech recognition and translation for each test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_audio = []\n",
    "all_transcriptions = []\n",
    "all_true_transcriptions = []\n",
    "all_translations = []\n",
    "\n",
    "for i in tqdm(range(len(test_dataset))):\n",
    "    example = test_dataset[i]\n",
    "    all_true_transcriptions.append(example['text'])\n",
    "    \n",
    "    audio = librosa.resample(\n",
    "        example['audio']['array'],\n",
    "        orig_sr=example['audio']['sampling_rate'],\n",
    "        target_sr=16000)\n",
    "\n",
    "    transcription = whisper_pipeline(audio)['text']\n",
    "    translation = translate_sentences(transcription, 'lug', 'eng')\n",
    "\n",
    "    all_audio.append(audio)\n",
    "    all_transcriptions.append(transcription)\n",
    "    all_translations.append(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute WER and take a look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word error rate: 0.650\n"
     ]
    }
   ],
   "source": [
    "normalizer = BasicTextNormalizer()\n",
    "wer_metric = evaluate.load(\"wer\", trust_remote_code=True)\n",
    "wer_score = wer_metric.compute(\n",
    "    predictions=[normalizer(p) for p in all_transcriptions],\n",
    "    references=[normalizer(r) for r in all_true_transcriptions])\n",
    "print(f'Word error rate: {wer_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.DataFrame()\n",
    "processed['audio'] = all_audio\n",
    "processed['transcription_truth'] = all_true_transcriptions\n",
    "processed['transcription_predicted'] = all_transcriptions\n",
    "processed['translation_predicted'] = all_translations\n",
    "salt.utils.show_dataset(datasets.Dataset.from_pandas(processed), audio_features=['audio'], N=len(processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
