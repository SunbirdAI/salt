{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pld_rq1XtZbd"
   },
   "source": [
    "## Sunbird ASR evaluation\n",
    "\n",
    "Application of the fine-tuned Whisper pipeline to the `ucfd_lug` and `ucfd_eng` test splits in [salt-practical-eval](https://huggingface.co/datasets/Sunbird/salt-practical-eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDEFy_3U0OB3"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q evaluate jiwer\n",
    "!pip install -q transformers\n",
    "!pip install -q librosa\n",
    "!pip install -q soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ThhtZdrE00cJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "from evaluate import load\n",
    "import evaluate\n",
    "import huggingface_hub\n",
    "from tqdm.notebook import tqdm\n",
    "import transformers\n",
    "import peft\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_hub.notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and set up an ASR pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6IdhCg22ay-",
    "outputId": "82eeee67-ebe1-4677-8854-6320c82f79cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80a1cc1e1d9483497452bce57c5c3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "whisper_pipeline = transformers.pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model = \"jq/whisper-large-v2-multilingual-prompts-corrected\",\n",
    "    device = device,\n",
    "    torch_dtype=torch.float16,\n",
    "    model_kwargs=({\"attn_implementation\": \"sdpa\"}),  # Maybe a speedup?\n",
    ")\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the WER metric for each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoWOFi7tVdnV",
    "outputId": "7a3dc81c-9149-400a-e193-8812697b943b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab536c158074fc69fdfdd5e9ff5cc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ucfd_eng WER: 0.254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f8e2657055428798dafca2d982e512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Prompt 1: set the context of the speech.\n",
    "# prompt_ids = whisper_pipeline.tokenizer.get_prompt_ids(\n",
    "#     'Thank you for calling dfcu bank. How can I help you? ',\n",
    "#     return_tensors='pt',\n",
    "# ).to('cuda')\n",
    "\n",
    "# #Prompt 2: Set the context in Luganda.\n",
    "# prompt_ids = whisper_pipeline.tokenizer.get_prompt_ids(\n",
    "#     'Webale kuwagira dfcu bank. Nkuyambe ntya leero? ',\n",
    "#     return_tensors='pt',\n",
    "# ).to('cuda')\n",
    "\n",
    "# Prompt 3: add vocabulary then set context.\n",
    "prompt_ids = whisper_pipeline.tokenizer.get_prompt_ids(\n",
    "    'dfcu, Quick Banking app, QuickApp, Quick Online, Quick Banking platform, '\n",
    "    'dfcu Personal Banking, mobile app, App store, Google Play Store, '\n",
    "    'dfcu Quick Online, Quick Connect, internet banking, mobile banking, '\n",
    "    'smartphone, national ID, passport, trust factor, Pinnacle Current Account,'\n",
    "    ' dfcu SACCO account, savings account, Dembe account, Smart Plan account, '\n",
    "    'Campus Plus account, Young Savers account, investment club account, '\n",
    "    'joint account, Secondary Account Ku-Spot, personal loan, mobi loan, save '\n",
    "    'for loan, home loan, agent banking, banking security, '\n",
    "    '6th Street, Abayita Ababiri, Bugolobi, Bwaise, Entebbe Road, Impala, '\n",
    "    'Jinja Road, Kampala Road, Kawempe, Kikuubo, Kireka, Kyadondo, Kyambogo, '\n",
    "    'Lugogo, Makerere, Market Street, Naalya, Nabugabo, Sun City, Acacia, '\n",
    "    'Entebbe Town, Kyengera, Luwum Street, Nateete, Ndeeba, Nsambya, Ntinda '\n",
    "    'Shopping Centre (Capital Shoppers), Ntinda Trading Centre, Owino, '\n",
    "    'William Street, Abim, Arua, Dokolo, Gulu, Hoima, Ibanda, Iganga, Ishaka, '\n",
    "    'Isingiro, Jinja, Kabale, Kisoro, Kitgum, Lira, Luweero, Lyantonde, '\n",
    "    'Masaka, Mbale, Mbarara, Mukono, Ntungamo, Pader, Pallisa, Rushere, '\n",
    "    'Soroti, Tororo. '\n",
    "    'Thank you for calling dfcu bank. How can I help you? ',\n",
    "    return_tensors='pt',\n",
    ").to('cuda')\n",
    "\n",
    "\n",
    "# Then call the pipeline with prompts specified as follows.\n",
    "generate_kwargs = {\n",
    "    \"prompt_ids\": prompt_ids,\n",
    "    \"prompt_condition_type\": \"first-segment\",\n",
    "    \"condition_on_prev_tokens\": True,\n",
    "    \"language\": None, \n",
    "    \"task\": \"transcribe\",\n",
    "    \"num_beams\": 1,\n",
    "}\n",
    "\n",
    "for subset in [\"ucfd_eng\", \"ucfd_lug\"]:\n",
    "    eval_dataset = datasets.load_dataset(\"Sunbird/salt-practical-eval\", subset, split=\"test\")\n",
    "    predictions = []\n",
    "    references = [example[\"text\"] for example in eval_dataset]\n",
    "\n",
    "    # TODO: Get batching working for ucfd_eng\n",
    "    for out in tqdm(whisper_pipeline(\n",
    "        transformers.pipelines.pt_utils.KeyDataset(eval_dataset, \"audio\"), batch_size=1,\n",
    "        generate_kwargs=generate_kwargs)\n",
    "    ):\n",
    "        predictions.extend([out['text']])\n",
    "\n",
    "    normalizer = BasicTextNormalizer()\n",
    "    wer_score = wer_metric.compute(\n",
    "        predictions=[normalise(p) for p in predictions],\n",
    "        references=[normalise(r) for r in references]\n",
    "    )\n",
    "    \n",
    "    print(f\"{subset } WER: {wer_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
