{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDEFy_3U0OB3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install evaluate jiwer\n",
        "!pip install pyctcdecode\n",
        "!pip install kenlm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import Dataset, Audio\n",
        "from evaluate import load\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "from transformers import (\n",
        "    Wav2Vec2ForCTC,\n",
        "    Wav2Vec2CTCTokenizer,\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2Processor,\n",
        "    Wav2Vec2ProcessorWithLM,\n",
        "    AutomaticSpeechRecognitionPipeline,\n",
        "    AutoProcessor,\n",
        ")\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "ThhtZdrE00cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "U9tb5HHX0_Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_ucfd.zip >> /dev/null"
      ],
      "metadata": {
        "id": "5z7T7I851HvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd eval_ucfd/"
      ],
      "metadata": {
        "id": "67D3VlSB1tGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('eval_df.csv')"
      ],
      "metadata": {
        "id": "23TZfp-_1tuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ucfd_eval_data = Dataset.from_dict(\n",
        "    {'audio': df.filename.to_list(), 'transcription': df.transcript.to_list()}\n",
        "    ).cast_column('audio', Audio())\n",
        "\n",
        "ucfd_eval_data"
      ],
      "metadata": {
        "id": "76SITpq22HUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITILy0Oo9kHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "5hSFREzz4XYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "whisperbase = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"openai/whisper-base\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "# facebookmms = pipeline(\n",
        "#     \"automatic-speech-recognition\",\n",
        "#     model = \"facebook/mms-1b-all\",\n",
        "#     device = device\n",
        "# )\n",
        "\n",
        "whisperSBFinetuned = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"akera/whisper-base-sb-english\",\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "N6IdhCg22ay-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"facebook/mms-1b-all\"\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_id).to(device)\n",
        "\n",
        "# Processor setup\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_id)\n",
        "\n",
        "\n",
        "tokenizer.set_target_lang(\"lug\")\n",
        "model.load_adapter(\"lug\")\n",
        "\n",
        "\n",
        "# Feature extractor setup\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(\n",
        "    feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True\n",
        ")\n",
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "vocab_dict = processor.tokenizer.get_vocab()\n",
        "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
        "\n",
        "\n",
        "\n",
        "use_lm = False\n",
        "\n",
        "if use_lm:\n",
        "\n",
        "  # Language model file setup\n",
        "  lm_file_name = \"eng_5gram.bin\"\n",
        "  lm_file_subfolder = \"language_model\"\n",
        "  lm_file = hf_hub_download(\n",
        "      repo_id=lang_config[\"eng\"],\n",
        "      filename=lm_file_name,\n",
        "      subfolder=lm_file_subfolder,\n",
        "  )\n",
        "\n",
        "  # Decoder setup -> Use KenLM as decoder\n",
        "  decoder = build_ctcdecoder(\n",
        "      labels=list(sorted_vocab_dict.keys()),\n",
        "      kenlm_model_path=lm_file,\n",
        "  )\n",
        "\n",
        "  # Use the lm as the Processor\n",
        "  processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "      feature_extractor=feature_extractor,\n",
        "      tokenizer=tokenizer,\n",
        "      decoder=decoder,\n",
        "  )\n",
        "  feature_extractor._set_processor_class(\"Wav2Vec2ProcessorWithLM\")\n",
        "\n",
        "\n",
        "  # ASR Pipeline, with a chunk and stride --> Make it work for even super long audio\n",
        "  facebookmms = AutomaticSpeechRecognitionPipeline(\n",
        "      model=model,\n",
        "      tokenizer=processor_with_lm.tokenizer,\n",
        "      feature_extractor=processor_with_lm.feature_extractor,\n",
        "      decoder=processor_with_lm.decoder,\n",
        "      device=device,\n",
        "      chunk_length_s=10,\n",
        "      stride_length_s=(4, 2),\n",
        "      return_timestamps=\"word\"\n",
        "  )\n",
        "\n",
        "else:\n",
        "  facebookmms = AutomaticSpeechRecognitionPipeline(\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "      feature_extractor=feature_extractor,\n",
        "      decoder=processor.decode,\n",
        "      device=device,\n",
        "      chunk_length_s=10,\n",
        "      stride_length_s=(4, 2),\n",
        "      return_timestamps=\"word\"\n",
        "  )\n"
      ],
      "metadata": {
        "id": "YE3etqNUzNIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_config = {\n",
        "    \"eng\": \"Sunbird/sunbird-mms\",\n",
        "}\n",
        "\n",
        "model_id = \"Sunbird/sunbird-mms\"\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_id).to(device)\n",
        "\n",
        "# Processor setup\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_id)\n",
        "\n",
        "\n",
        "tokenizer.set_target_lang(\"eng\")\n",
        "model.load_adapter(\"eng\")\n",
        "\n",
        "\n",
        "# Feature extractor setup\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(\n",
        "    feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True\n",
        ")\n",
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "vocab_dict = processor.tokenizer.get_vocab()\n",
        "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Language model file setup\n",
        "lm_file_name = \"eng_5gram.bin\"\n",
        "lm_file_subfolder = \"language_model\"\n",
        "lm_file = hf_hub_download(\n",
        "    repo_id=lang_config[\"eng\"],\n",
        "    filename=lm_file_name,\n",
        "    subfolder=lm_file_subfolder,\n",
        ")\n",
        "\n",
        "# Decoder setup -> Use KenLM as decoder\n",
        "decoder = build_ctcdecoder(\n",
        "    labels=list(sorted_vocab_dict.keys()),\n",
        "    kenlm_model_path=lm_file,\n",
        ")\n",
        "\n",
        "# Use the lm as the Processor\n",
        "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "    feature_extractor=feature_extractor,\n",
        "    tokenizer=tokenizer,\n",
        "    decoder=decoder,\n",
        ")\n",
        "feature_extractor._set_processor_class(\"Wav2Vec2ProcessorWithLM\")\n",
        "\n",
        "\n",
        "# ASR Pipeline, with a chunk and stride --> Make it work for even super long audio\n",
        "sunbirdmms = AutomaticSpeechRecognitionPipeline(\n",
        "    model=model,\n",
        "    tokenizer=processor_with_lm.tokenizer,\n",
        "    feature_extractor=processor_with_lm.feature_extractor,\n",
        "    decoder=processor_with_lm.decoder,\n",
        "    device=device,\n",
        "    chunk_length_s=10,\n",
        "    stride_length_s=(4, 2),\n",
        "    return_timestamps=\"word\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "71GdV9EC4onC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facebookmmspredictions = []\n",
        "for prediction in facebookmms(KeyDataset(ucfd_eval_data, 'audio')):\n",
        "  facebookmmspredictions.append(prediction['text'])\n"
      ],
      "metadata": {
        "id": "u2V_UMW02cws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facebookmmspredictions"
      ],
      "metadata": {
        "id": "P3ai8jbV2uag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "Mwl81kA78fYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "whisperbasepredictions, facebookmmspredictions, sunbirdmmspredictions, whispersbfinetunedpredictions = [], [], [],  []\n",
        "\n",
        "for prediction in sunbirdmms(KeyDataset(ucfd_eval_data, 'audio')):\n",
        "  sunbirdmmspredictions.append(prediction['text'])\n",
        "\n",
        "\n",
        "for prediction in whisperbase(KeyDataset(ucfd_eval_data, 'audio')):\n",
        "  whisperbasepredictions.append(prediction['text'])\n",
        "\n",
        "for prediction in facebookmms(KeyDataset(ucfd_eval_data, 'audio')):\n",
        "  facebookmmspredictions.append(prediction['text'])\n",
        "\n",
        "\n",
        "for prediction in whisperSBFinetuned(KeyDataset(ucfd_eval_data, 'audio')):\n",
        "  whispersbfinetunedpredictions.append(prediction['text'])"
      ],
      "metadata": {
        "id": "XNduK2AP5_j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate WER"
      ],
      "metadata": {
        "id": "dJaJ1vRu7v9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer_metric = load(\"wer\")"
      ],
      "metadata": {
        "id": "TFheEUuG7vmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer_whisperbase = 100 * wer_metric.compute(\n",
        "    references=ucfd_eval_data[\"transcription\"], predictions=whisperbasepredictions\n",
        ")\n",
        "wer_facebookmms = 100 * wer_metric.compute(\n",
        "    references=ucfd_eval_data[\"transcription\"], predictions=facebookmmspredictions\n",
        ")\n",
        "wer_sunbirdmms = 100 * wer_metric.compute(\n",
        "    references=ucfd_eval_data[\"transcription\"], predictions=sunbirdmmspredictions\n",
        ")\n",
        "\n",
        "wer_whisperSBFinetuned = 100 * wer_metric.compute(\n",
        "    references=ucfd_eval_data[\"transcription\"], predictions=whispersbfinetunedpredictions\n",
        ")"
      ],
      "metadata": {
        "id": "IKiVJ14H7YXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"WhisperBase WER: {wer_whisperbase:.2f}%\")\n",
        "print(f\"FacebookMMS WER: {wer_facebookmms:.2f}%\")\n",
        "print(f\"SunbirdMMS WER: {wer_sunbirdmms:.2f}%\")\n",
        "print(f\"WhisperSBFinetuned WER: {wer_whisperSBFinetuned:.2f}%\")"
      ],
      "metadata": {
        "id": "N6DUx99I9dGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions(predictions1, predictions2, predictions3, predictions4, ground_truths):\n",
        "    for idx, (pred1, pred2, pred3, pred4, truth) in enumerate(zip(predictions1, predictions2, predictions3, predictions4, ground_truths)):\n",
        "        print(f\"Example {idx + 1}:\")\n",
        "        print(f\"  Ground Truth: {truth}\")\n",
        "        print(f\"  Wspr-FineTuned: {pred1}\")\n",
        "        print(f\"  SB-MMS: {pred2}\")\n",
        "        print(f\"  Wspr-Base: {pred3}\")\n",
        "        print(f\"  FacebookMMS: {pred4}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "whispersbfinetunedpredictions = whispersbfinetunedpredictions\n",
        "sunbirdmmspredictions = sunbirdmmspredictions\n",
        "whisperbasepredictions = whisperbasepredictions\n",
        "facebookmmspredictions = facebookmmspredictions\n",
        "ground_truths = ucfd_eval_data[\"transcription\"]\n",
        "\n",
        "compare_predictions(whispersbfinetunedpredictions, sunbirdmmspredictions, whisperbasepredictions, facebookmmspredictions, ground_truths)"
      ],
      "metadata": {
        "id": "-NPxBNIefz95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whispersbfinetunedpredictions"
      ],
      "metadata": {
        "id": "H2qfArONiM3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}