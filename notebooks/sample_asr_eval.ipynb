{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunbirdAI/salt/blob/main/notebooks/sample_asr_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sunbird ASR evaluation"
      ],
      "metadata": {
        "id": "pld_rq1XtZbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run ASR eval for SB and other models on our partner datasets\n",
        "#\n",
        "# Notebook location:\n",
        "# 'Shared drives/Sunbird AI/Projects/African Language Technology/ASR Evaluation'\n",
        "#\n",
        "# Ideally we should move all the eval data once its stable to\n",
        "# SB huggingface and call it from there.\n",
        "#\n",
        "# Goal is to link the notebook to a leaderboard, where results are\n",
        "# automatically updated for the different models as a way of tracking\n",
        "# model improvements."
      ],
      "metadata": {
        "id": "CtP7J_CNuTw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wDEFy_3U0OB3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install evaluate jiwer\n",
        "!pip install pyctcdecode\n",
        "!pip install kenlm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import stuff\n",
        "\n",
        "import os\n",
        "import json\n",
        "import string\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import Dataset, Audio\n",
        "from evaluate import load\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "from transformers import (\n",
        "    Wav2Vec2ForCTC,\n",
        "    Wav2Vec2CTCTokenizer,\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2Processor,\n",
        "    Wav2Vec2ProcessorWithLM,\n",
        "    AutomaticSpeechRecognitionPipeline,\n",
        "    AutoProcessor,\n",
        ")\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "from transformers import pipeline\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "ThhtZdrE00cJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/gdrive')\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "U9tb5HHX0_Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512bdff6-b7d8-4f37-e10f-157c386a3b77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch eval data\n",
        "Currently data is fetched from Google Drive. Once the data is stable, data can be moved to SB huggingface and fetched directly."
      ],
      "metadata": {
        "id": "sLT3on6TwcQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_ucfd_eng.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_ucfd_lug.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_sema_eng.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_sema_lug.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_trac_fm_lug.zip >> /dev/null"
      ],
      "metadata": {
        "id": "5z7T7I851HvJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load eval data\n",
        "\n",
        "def load_eval_data(folder_path):\n",
        "  # Load eval dataset\n",
        "  csv_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.csv')]\n",
        "\n",
        "  if not csv_files:\n",
        "      raise FileNotFoundError(\"No CSV file found in the folder.\")\n",
        "\n",
        "  csv_file_path = os.path.join(folder_path, csv_files[0])\n",
        "\n",
        "  df = pd.read_csv(csv_file_path)\n",
        "\n",
        "  # Check if 'filename' column exists in the CSV file\n",
        "  if 'filename' not in df.columns:\n",
        "      raise ValueError(\"'filename' column not found in the CSV file.\")\n",
        "\n",
        "  # Add the folder path to each entry in the 'filename' column\n",
        "  df['filename'] = df['filename'].apply(lambda x: os.path.join(folder_path, x))\n",
        "\n",
        "  eval_data = Dataset.from_dict(\n",
        "  {'audio': df.filename.to_list(), 'transcription': df.transcription.to_list()}\n",
        "  ).cast_column('audio', Audio())\n",
        "\n",
        "  return eval_data\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ir8HOqE0xZIi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ucfd_eng_eval_data = load_eval_data('eval_ucfd_eng')\n",
        "ucfd_lug_eval_data = load_eval_data('eval_ucfd_lug')\n",
        "sema_eng_eval_data = load_eval_data('eval_sema_eng')\n",
        "sema_lug_eval_data = load_eval_data('eval_sema_lug')\n",
        "trac_fm_lug_eval_data = load_eval_data('eval_trac_fm_lug')"
      ],
      "metadata": {
        "id": "67D3VlSB1tGr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sema_eng_eval_data"
      ],
      "metadata": {
        "id": "ITILy0Oo9kHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea11edb-c1f6-46a5-89ae-4859b2025e08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['audio', 'transcription'],\n",
              "    num_rows: 12\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Models\n",
        "\n",
        "def wav2vecpipeline(model_id, lang, lm_file, device=device, use_lm=True):\n",
        "  # Get Wav2Vec2ForCTC model based transformer pipeline\n",
        "  model = Wav2Vec2ForCTC.from_pretrained(model_id).to(device)\n",
        "\n",
        "  # Processor setup\n",
        "  processor = AutoProcessor.from_pretrained(model_id)\n",
        "  tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_id)\n",
        "\n",
        "  tokenizer.set_target_lang(lang)\n",
        "  model.load_adapter(lang)\n",
        "\n",
        "\n",
        "  # Feature extractor setup\n",
        "  feature_extractor = Wav2Vec2FeatureExtractor(\n",
        "      feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True\n",
        "  )\n",
        "  processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "  vocab_dict = processor.tokenizer.get_vocab()\n",
        "  sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
        "\n",
        "  if use_lm:\n",
        "\n",
        "    # Language model file setup\n",
        "    lm_file_name = lm_file\n",
        "    lm_file_subfolder = \"language_model\"\n",
        "    lm_file = hf_hub_download(\n",
        "        repo_id=model_id,\n",
        "        filename=lm_file_name,\n",
        "        subfolder=lm_file_subfolder,\n",
        "    )\n",
        "\n",
        "    # Decoder setup -> Use KenLM as decoder\n",
        "    decoder = build_ctcdecoder(\n",
        "        labels=list(sorted_vocab_dict.keys()),\n",
        "        kenlm_model_path=lm_file,\n",
        "    )\n",
        "\n",
        "    # Use the lm as the Processor\n",
        "    processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "        feature_extractor=feature_extractor,\n",
        "        tokenizer=tokenizer,\n",
        "        decoder=decoder,\n",
        "    )\n",
        "    feature_extractor._set_processor_class(\"Wav2Vec2ProcessorWithLM\")\n",
        "\n",
        "    # ASR Pipeline, with a chunk and stride --> Make it work for even super long audio\n",
        "    pipe = AutomaticSpeechRecognitionPipeline(\n",
        "        model=model,\n",
        "        tokenizer=processor_with_lm.tokenizer,\n",
        "        feature_extractor=processor_with_lm.feature_extractor,\n",
        "        decoder=processor_with_lm.decoder,\n",
        "        device=device,\n",
        "        chunk_length_s=10,\n",
        "        stride_length_s=(4, 2),\n",
        "        return_timestamps=\"word\"\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    pipe = AutomaticSpeechRecognitionPipeline(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        feature_extractor=feature_extractor,\n",
        "        decoder=processor.decode,\n",
        "        device=device,\n",
        "        chunk_length_s=10,\n",
        "        stride_length_s=(4, 2),\n",
        "        return_timestamps=\"word\"\n",
        "    )\n",
        "\n",
        "  return pipe"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tp4mvljU4JUg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisperbase = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"openai/whisper-base\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "facebookmms = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"facebook/mms-1b-all\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "whisperSBFinetuned = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"akera/whisper-base-sb-english\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "sunbirdmms = wav2vecpipeline(\n",
        "    model_id = \"Sunbird/sunbird-mms\",\n",
        "    lang = \"eng\",\n",
        "    lm_file = \"eng_5gram.bin\",\n",
        "    device = device,\n",
        "    use_lm = True,\n",
        ")\n",
        "\n",
        "facebooklugmms = wav2vecpipeline(\n",
        "    model_id = \"facebook/mms-1b-all\",\n",
        "    lang = \"lug\",\n",
        "    lm_file = \"lug_eng_5gram.bin\",\n",
        "    device = device,\n",
        "    use_lm = False\n",
        ")"
      ],
      "metadata": {
        "id": "N6IdhCg22ay-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions\n",
        "\n",
        "def get_predictions(pipeline, eval_datasets):\n",
        "  eval_predictions = {}\n",
        "  for eval_name, eval_data in eval_datasets.items():\n",
        "    predictions = []\n",
        "    for prediction in pipeline(eval_data['audio']):\n",
        "      predictions.append(prediction['text'])\n",
        "    eval_predictions[eval_name] = predictions\n",
        "  return eval_predictions"
      ],
      "metadata": {
        "id": "KDbfZFIu_UbV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_eval_datasets = {\n",
        "    \"ucfd_eng\": ucfd_eng_eval_data,\n",
        "    \"sema_eng\": sema_eng_eval_data,\n",
        "}\n",
        "\n",
        "lug_eval_datasets = {\n",
        "    \"ucfd_lug\": ucfd_lug_eval_data,\n",
        "    \"sema_lug\": sema_lug_eval_data,\n",
        "    \"trac_fm_lug\": trac_fm_lug_eval_data\n",
        "}"
      ],
      "metadata": {
        "id": "4y8UIX3DA9ij"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eng eval\n",
        "whisperbasepredictions = get_predictions(whisperbase, eng_eval_datasets)\n",
        "facebookmmspredictions = get_predictions(facebookmms, eng_eval_datasets)\n",
        "sunbirdmmspredictions = get_predictions(sunbirdmms, eng_eval_datasets)\n",
        "whispersbfinetunedpredictions = get_predictions(whisperSBFinetuned, eng_eval_datasets)"
      ],
      "metadata": {
        "id": "AAR8rNKOBT1f"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lug eval\n",
        "facebooklugmmspredictions = get_predictions(facebooklugmms, lug_eval_datasets)"
      ],
      "metadata": {
        "id": "mWLmSSAaCZhV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate WER\n",
        "\n",
        "def lower_case_and_strip_punctuation(string_list, allowed_punctuation=\"'\"):\n",
        "  '''Convert a list of strings by converting to lower case and removing\n",
        "  punctuation. This helps when calculating WER, as we're interested in which\n",
        "  words were predicted more than the capitalisation or punctuation.'''\n",
        "  result = []\n",
        "  for s in string_list:\n",
        "    s = s.lower()\n",
        "    punct = list(string.punctuation)\n",
        "    if allowed_punctuation:\n",
        "        for allowed in allowed_punctuation:\n",
        "            punct.remove(allowed)\n",
        "    result.append(''.join([c for c in s if c not in punct]))\n",
        "  return result\n",
        "\n",
        "def get_wer(predictions, datasets):\n",
        "  wer_metric = load(\"wer\")\n",
        "  output_wer = {}\n",
        "  for eval_name, eval_data in datasets.items():\n",
        "    wer = 100 * wer_metric.compute(\n",
        "        references=lower_case_and_strip_punctuation(eval_data[\"transcription\"]),\n",
        "        predictions=lower_case_and_strip_punctuation(predictions[eval_name]),\n",
        "    )\n",
        "    output_wer[eval_name] = round(wer, 2)\n",
        "  return output_wer\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZsRoczZXDhLi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer_whisperbase = get_wer(whisperbasepredictions, eng_eval_datasets)\n",
        "wer_facebookmms = get_wer(facebookmmspredictions, eng_eval_datasets)\n",
        "wer_sunbirdmms = get_wer(sunbirdmmspredictions, eng_eval_datasets)\n",
        "wer_whisperSBFinetuned = get_wer(whispersbfinetunedpredictions, eng_eval_datasets)\n",
        "wer_facebooklugmms = get_wer(facebooklugmmspredictions, lug_eval_datasets)"
      ],
      "metadata": {
        "id": "Elwx1K3fEDjf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Whisperbase WER: {json.dumps(wer_whisperbase, indent=4)}\")\n",
        "print(f\"FacebookMMS WER: {json.dumps(wer_facebookmms, indent=4)}\")\n",
        "print(f\"SunbirdMMS WER: {json.dumps(wer_sunbirdmms, indent=4)}\")\n",
        "print(f\"SWhisperSBFinetuned WER: {json.dumps(wer_whisperSBFinetuned, indent=4)}\")\n",
        "print(f\"FacebookLugMMS WER: {json.dumps(wer_facebooklugmms, indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SOQUnpuGm0",
        "outputId": "c8fc548d-a52e-4251-84f9-2fcbf07818ae"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisperbase WER: {\n",
            "    \"ucfd_eng\": 65.1,\n",
            "    \"sema_eng\": 85.31\n",
            "}\n",
            "FacebookMMS WER: {\n",
            "    \"ucfd_eng\": 90.25,\n",
            "    \"sema_eng\": 80.81\n",
            "}\n",
            "SunbirdMMS WER: {\n",
            "    \"ucfd_eng\": 53.32,\n",
            "    \"sema_eng\": 50.47\n",
            "}\n",
            "SWhisperSBFinetuned WER: {\n",
            "    \"ucfd_eng\": 46.6,\n",
            "    \"sema_eng\": 47.16\n",
            "}\n",
            "FacebookLugMMS WER: {\n",
            "    \"ucfd_lug\": 84.8,\n",
            "    \"sema_lug\": 87.86,\n",
            "    \"trac_fm_lug\": 63.22\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions(predictions1, predictions2, predictions3, predictions4, ground_truths):\n",
        "    for idx, (pred1, pred2, pred3, pred4, truth) in enumerate(zip(predictions1, predictions2, predictions3, predictions4, ground_truths)):\n",
        "        print(f\"Example {idx + 1}:\")\n",
        "        print(f\"  Ground Truth: {truth}\")\n",
        "        print(f\"  Wspr-FineTuned: {pred1}\")\n",
        "        print(f\"  SB-MMS: {pred2}\")\n",
        "        print(f\"  Wspr-Base: {pred3}\")\n",
        "        print(f\"  FacebookMMS: {pred4}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "ds = 'trac_fm_lug'\n",
        "\n",
        "if ds != 'trac_fm_lug':\n",
        "    whispersbfinetunedpredictions = whispersbfinetunedpredictions[ds]\n",
        "    sunbirdmmspredictions = sunbirdmmspredictions[ds]\n",
        "    whisperbasepredictions = whisperbasepredictions[ds]\n",
        "    facebookmmspredictions = facebookmmspredictions[ds]\n",
        "    ground_truths = eng_eval_datasets[ds][\"transcription\"]\n",
        "\n",
        "    compare_predictions(whispersbfinetunedpredictions, sunbirdmmspredictions, whisperbasepredictions, facebookmmspredictions, ground_truths)\n",
        "else:\n",
        "    predictions = facebooklugmmspredictions[ds]\n",
        "    ground_truths = lug_eval_datasets[ds][\"transcription\"]\n",
        "    for idx, pred in enumerate(zip(predictions, ground_truths)):\n",
        "        print(f\"Example {idx + 1}:\")\n",
        "        print(f\"  Ground Truth: {ground_truths[idx]}\")\n",
        "        print(f\"  FacebookLugMMS: {pred[0]}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "-NPxBNIefz95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89ef56f-1f06-4351-9ee8-f69818523a3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "  Ground Truth: Option B,Yee, kukyaalo kyaffe waaliwo omusomo ogw'ebyetaka, nategeera ddi lwenyina okukuuma etaka lyange na ddi lwenyina okulikozesa mubutuufu nga teli muntu yena bwekoseza na ddi lwendi yina ko obwa nanyini.\n",
            "  FacebookLugMMS: option ba ye ku kyalo kyaffe waliyo omusomo gw'ebyettaka nategeera dd lwenina okuuma ettaka lyange naddi lwennina olikozesa mu butuufu nga teri muntu yena bwenkoseza naddi lwendirinako obwananyini\n",
            "\n",
            "Example 2:\n",
            "  Ground Truth: mwasuze mutya ba memba, mba lamusizaako mwena, Nze okusinzira ku kibuuzo ekya leero, nyenda ne kya. Simanyi butya ddembe ly'omuntu welitekeddwa ku beera ku, okusinzira ku enaku zino bye tuyitamu enakuzino, era nze mbadde simanyi nti eddembe ly'obuntu ku bulamu bwa nge nti ndye taaga kubanga bulikimu nkiyitamu buyisi, sibitegeera ko daala ku kye bayita ddembe lyobuntu.\n",
            "  FacebookLugMMS: mwasuze muti abamemba alamusizaako mwena nze okusinziira okibuuzo ekya leero ngenda nekya simanyi buty eddembe lya muntu weliteekeddwa kubeera okusinziira ku naku zino byetuyitamu era nze mbadde kimanyi nti eddembe ly'obuntu ku bulamu bwange nti ndyetaaga kubanga buli kimu kiyitamu buyisi sibitegeerako dala ku kibayita eddembe lyobuntu\n",
            "\n",
            "Example 3:\n",
            "  Ground Truth: Aah Eky'okuddamu kili B, nti ye, ku kyalo kyaffe, ekitongole kya Justice Center for Democracy, kyategeka olukungaana ne ki somesa ku ddembe, ddala ku by'obusikka ne ngeri gyetukola mu amalame, era twayiga, era nga nze omu nayigga butya weyinza okukola n'okumanaya eddembe lyange.\n",
            "  FacebookLugMMS: ekyokuddamu kiribba nti ye ku kyalo kyaffe ekitongole kya jusitis centa for democracy kyategeka oluku≈ãgaana nekisomesa ku ddembe ddala ku byobusika naye ngeri gyetukolamu amalaame era twayiga era nga nz' omu nnayiga butya wennyinza okukola n'okumanya eddembe lyange\n",
            "\n",
            "Example 4:\n",
            "  Ground Truth: Ba memba ,mba lamusizza, aa nze Ssalongo Ndawula . Ekyokuddamu ekyange nno kili B, Yee nasobola okufuna amawulire agakwata kuddembe lyange nga mpitta mu misomo egyitegekebwa , oluusi ne ku radiyoz,na ddala ladio Simba eyo ,eteera nnyo okutegeka programu naye nga zi kwatira ku muntu wabuligyo ne ddembe lyaffe\n",
            "  FacebookLugMMS: bamemba balamusiza anze esaalo mundawula ekyokuddamu ekyanga eno kiri ba ye nasobola okufuna amawulire agakwata ku ddembe lyange mampita mu misomo egitegekebwa olusine ku lwediyozi nadala laediyosimba eyo atera nnyo okutegeka pulogulaamu ane nga zikwatyaddaako muntu owa bulijjo n'eddembe lyaffe\n",
            "\n",
            "Example 5:\n",
            "  Ground Truth: Ba memba mba lamusizza, Ssalongo Ndawula, nze nkomyewo kubanga eddoboozi lyange lyasusiza obutikiti amakumi asatu. Aaa , Ekituufu eddembe lyange , ekyalo kyategekaako n'aba Justice Center for Democracy ne ba jja ne basomesa ku ddembe lya buntu ne kilala, radio Simba nga bwe nabagambye nayo ebadenga ekola nnyo okutusomesa kati kyanyamba ko okumanya eddembe lyange.\n",
            "  FacebookLugMMS: bamemam balamusiza saalongo ndawula nze nkomyewo kubanga eddoboozi lyange lyasusiza obutikiti amakumi asatu ekituufu eddembe lyange ekyalo kyategekako okunabaja cit center for democrac ne bajja ne basomesa ku ddembe lya buntu naye kiroa lediyo siima nga bwe nabagambye nayo ebadde nga ekola nnyo okutusomesa ekyanyambako okumanya eddembe lyange\n",
            "\n",
            "Example 6:\n",
            "  Ground Truth: Era mbadde nga ngoberera nnyo ekitongole ekya Global Peace Foundation nga nakyo kinyamba ko nnyo okumanya eddembe lyange, eee, mwami kambura milton oyo Peace Ambassador, ee mbadde nteera nyo ku mu saanga n'atusomesa ku ddembe lyaffe, era omwami mulungi nnyo. Kinyambye ko okumanya ddembe lyange na kutya weyinza okulikuuma.\n",
            "  FacebookLugMMS: era mbadde nga ngobelera nnyo ekitongole kya global peace foundation nga nakyo kinyambako nnyo okumanya eddembe lyange emwami kambura miritonne oyo pisa ambasada baddeenterannyo kumusikana n'atusomesa ku ddembe lyaffe era omwamyi mulungi nnyo kinyambyeko okumanya eddembe lyange labute bwennyinza okulikuuma\n",
            "\n",
            "Example 7:\n",
            "  Ground Truth: Bamemba musibyemutya eyo, kansubire musibye bulungi,elinnya nze Muwonge Eriya, ekituufu nange ogwo omulamwa ogukwatagana kuddembe lyobuntu nguwulira ku radio Simba nayenga mu kitundu kyange sigulabangako\n",
            "  FacebookLugMMS: bamemba musibe muty eyo kasiire musibe bulungi erinyanzi mu ongariakikufunange ogw'omulamu ogukwatagana ku ddembe ly'obuntu nguli ya ku lediyo si mba naye ngayanze mu kitundu kyange sigulabangako\n",
            "\n",
            "Example 8:\n",
            "  Ground Truth: Banange Eky okuddamu, simanyi na kya kuddamu kubanga nze eno mu kitundu gyembeera sifunna nga ku musomo gwonna, silabangako baletayo musomo gemazima, eno gyembeera ewaffe siyina kye yninza ku ddamu ku nsonga eno gye tuliko oba ku mulamwa gwe tu li ko\n",
            "  FacebookLugMMS: ananga ekyokuddamu simayina kyakuddamu kubanga nzene mu kitundu yembeera sifunanga ku musomo gwonna siraba nga kobaleetayo musomo gwe mazima eno gyembeera ewaffe era sirina kyanyinza kuddamu ku nsonga eno gye tuliko oba kumulamwa gwe tuliko\n",
            "\n",
            "Example 9:\n",
            "  Ground Truth: Mwasibye mu tya ba memba mwenna, abasilamu asalam alekum, abalokole na abasikadde mwenna mukama ayebazibwe, Amanya aga nge nze kasumba muzamil Ekyokuddamu kyange B lwansonga sifunangamu kusomesebwa kwonna likwata ku ddembe lyange okujjako radio simba lwemba njitezze nga pulogulamu eyo kweli nenji wuliriza naye ku kitundu kyange siji wulirangako ela nze ndi awo bwentyo omuntu newo mu gamba ninna ddembe lyange okukola kinno okubogolera nga bwayagala toyina bo jja mugambako kuba ye munene mu Ggwanga\n",
            "  FacebookLugMMS: mwasibye mutya bamemba muna abasilamusa bamalayikum abalokole abasigadde mwena mukama yebazime nannyaganyaeze kasomba mmekyangeo ekyokuddamu kyange bi lwansonga sifunangamu kusomesebwa kwonna kikwata ku ddembe lyange okuggako ediosi mba bemanjitezenga pulogula mwoyo kweri ne njiwuliza ne ku kitundu kyange siriwulirangako nganzenimndyawo bwe nti omunaomugamani n'eddembe erya nga okola kino okubogolera nga bwayagala tomina wonja mmugambako kuba ye munene muggwanga\n",
            "\n",
            "Example 10:\n",
            "  Ground Truth: Option D, Nageeza ko okufuna ku mawulire agakwata ku ddembe lyange naye nenemererwa\n",
            "  FacebookLugMMS: option da nagezaako okufuna ku mawulire agakwata ku ddembe lyange naye nenemererwa\n",
            "\n",
            "Example 11:\n",
            "  Ground Truth: I am so sorry mbadde seyanjudde manya, manya ne ddoboozi nze kasumba muzamil, option yange eli D Kubanga sifunangako kumanyisibwa kwonna ekikwata ku ddembe lyange nga omuntu.\n",
            "  FacebookLugMMS: amusosolo embade sayanjudde manya mannya edobooze nza kasumba mu zamiro opusioni yange eridda kubanga sifunangawo kumanyisibwa kwonna kikwata ku ddembe lyange ng'omuntu\n",
            "\n",
            "Example 12:\n",
            "  Ground Truth: Ba memba Musiibye mutya amanya nze Sekamate Muzamil wano emisolo kigongo Entebbe, nze ngenda ne B,  buli Obubaka bwa eddembe lyange mbu wulira ku radio simba naye siteera  kubugoberera nnyo sibulondoola.\n",
            "  FacebookLugMMS: managobamusibye mutya amanyi nzesekamate muzamiro wano emisoli kigongo entebe nenera ni b bibubaka bw'eddembe lyange buyira ku redio cimbe nayesitera kubugobereranyo sibulondoola\n",
            "\n",
            "Example 13:\n",
            "  Ground Truth: yee, eno ewaffe mubende emisomo bagyileeta era tujji funna ,ekyokuddamu njakulonda ko B , emisomo tukifuna bulungi lwakuba nti  ate  human rights commission yo eji somesa naye ate abaji tekesa munkola ddala nga police, omuli ogwabwe gulabika baagusuula tebakutekesa munkola nga bwe bayina tekesa munkola eddembe ly'obuntu\n",
            "  FacebookLugMMS: yaenewaffa emubende emisomo bagileeta era togifuna ebekyokuddamu nja kulondako bba emisomo togifuna bulungi akoba nti ate human rights commission yo egisomesa naye ate abagiteekesa mu nkola naddala nga poliisi omulimu ogwago akabaagusuula ntevakuteekesa mu nkola nga bwebalina kuteekesa munkola eddembe ly'obuntu\n",
            "\n",
            "Example 14:\n",
            "  Ground Truth: Ya eno ewaffe Mubende akwasaganya owa poliisi n'omuntu owa bulijo. Bambi, agezaako okuba enkungaana kumpi ku buli kyalo, ng'asomesa abantu eddembe lyabwe ate nga webayinza olikwatamu.  Mpozzi ne ku ma radio agenjawulo ela tumuwulila agewaffe eno. Awo ekyokudamu nja kulaba nge li B nga tubifuna nnyo, ngasomesa, mpozzi ne ku radio Simba okwo e batusomesa nyo, tubelako ebikwata ku ddembe lyafe.\n",
            "  FacebookLugMMS: ya eneaffe mubende akwasaganya wapoliisi n'omuntu owa bulijjo bambi agezaa ko kuba enkungaana kumpi ku buli kyalo ngaasomesa abantu eddembe lyabwe ngabatebwe bayinza olikwatamuzsi ne kumalidi agenjawulo era tumuwulira gewaffeeno awo ekyokuddamu nja kulaba ngaeri bbi watubifuna nnyo eyasomesa pozzi ne kulweddiro simba okwo eyiwatusomesa nnyo tubeerako nga tuwuli ebikwata ku ddembe lyaffe\n",
            "\n",
            "Example 15:\n",
            "  Ground Truth: Amanya nze lwampale Abraham, kuva  wano ekasese  munansonyiwa luganda luntawanyamu,naye answer yange eli B, sometimes tufuna enkiiko, obuzibu bwetufuna ,enkiiko zinno, batukubiriza nebatusomesa naye tebatera kuzitekesa munkola, bakoma oku tuyigiliza, no ku tuwulirira nokututegeeza naye teba tegeeza munkola ebiseera ebisinga\n",
            "  FacebookLugMMS: amanya nzebwampale abulahamu kubayana kasese munasonya oluganda lundawanyamu naye asa yange eriba samutayi muzitufuna enkko ae obuzibu bwetufuna ensiku zino batukubiriza ne batusomesa naye tebatera kuzitegesa mu nkola abakoma kutuyigiriza n'okutubulirira okututegeeza nayitibwa tutegesa mu nkola ebisera ebisinga\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2B5RrtvINSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}