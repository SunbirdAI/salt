{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunbirdAI/salt/blob/main/notebooks/ASR_correction_training_FLAN_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM22URX1IrV_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U transformers\n",
        "!pip install -U datasets\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses\n",
        "!pip install -q mlflow\n",
        "!pip install psutil\n",
        "!pip install pynvml\n",
        "\n",
        "!git clone https://github.com/sunbirdai/salt.git\n",
        "!pip install -r salt/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNCKY1wral2q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import evaluate\n",
        "import tqdm\n",
        "import salt.dataset\n",
        "import salt.utils\n",
        "import salt.metrics\n",
        "import yaml\n",
        "from IPython import display\n",
        "import getpass\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj7JXzyNu1AM"
      },
      "outputs": [],
      "source": [
        "# Set MLflow tracking credentials\n",
        "MLFLOW_TRACKING_USERNAME = getpass.getpass('Enter the MLFLOW_TRACKING_USERNAME: ') # enter your provided username\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = MLFLOW_TRACKING_USERNAME\n",
        "\n",
        "MLFLOW_TRACKING_PASSWORD = getpass.getpass('Enter the MLFLOW_TRACKING_PASSWORD: ') # enter your provided password\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = MLFLOW_TRACKING_PASSWORD\n",
        "\n",
        "# Set the MLflow tracking URI\n",
        "mlflow.set_tracking_uri('https://mlflow-sunbird-ce0ecfc14244.herokuapp.com/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qjZVzVsAqRU"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-btsrsNhZwt"
      },
      "outputs": [],
      "source": [
        "# define the artifacts directory for output files\n",
        "drive_folder = \"./artifacts\"\n",
        "\n",
        "if not os.path.exists(drive_folder):\n",
        "  %mkdir $drive_folder\n",
        "\n",
        "effective_train_batch_size = 3000\n",
        "train_batch_size = 15\n",
        "eval_batch_size = train_batch_size\n",
        "\n",
        "gradient_accumulation_steps = int(effective_train_batch_size / train_batch_size)\n",
        "\n",
        "# Everything in one yaml string, so that it can all be logged to MLFlow\n",
        "yaml_config = '''\n",
        "training_args:\n",
        "  output_dir: \"{drive_folder}\"\n",
        "  evaluation_strategy: steps\n",
        "  eval_steps: 10\n",
        "  save_steps: 40\n",
        "  warmup_steps: 10\n",
        "  num_train_epochs: 3\n",
        "  gradient_accumulation_steps: {gradient_accumulation_steps}\n",
        "  learning_rate: 3.0e-4  # Include decimal point to parse as float\n",
        "  per_device_train_batch_size: {train_batch_size}\n",
        "  per_device_eval_batch_size: {eval_batch_size}\n",
        "  weight_decay: 0.01\n",
        "  save_total_limit: 3\n",
        "  predict_with_generate: True\n",
        "  fp16: False\n",
        "  logging_dir: \"{drive_folder}\"\n",
        "  load_best_model_at_end: True\n",
        "  metric_for_best_model: loss\n",
        "  seed: 42\n",
        "  hub_model_id: asr-correction-flan-t5\n",
        "  push_to_hub: True\n",
        "\n",
        "mlflow_run_name: correction-with-ambiguity\n",
        "mlflow_experiment_name : asr-correction\n",
        "\n",
        "max_input_length: 224\n",
        "max_output_length: 224\n",
        "eval_pretrained_model: False\n",
        "early_stopping_patience: 4\n",
        "data_dir: .\n",
        "model_checkpoint: google/flan-t5-base\n",
        "'''\n",
        "\n",
        "yaml_config = yaml_config.format(\n",
        "    drive_folder=drive_folder,\n",
        "    train_batch_size=train_batch_size,\n",
        "    eval_batch_size=eval_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        ")\n",
        "\n",
        "config = yaml.safe_load(yaml_config)\n",
        "\n",
        "training_settings = transformers.Seq2SeqTrainingArguments(\n",
        "    **config[\"training_args\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Aer4abSStvM"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.T5Tokenizer.from_pretrained(config['model_checkpoint'])\n",
        "model = transformers.T5ForConditionalGeneration.from_pretrained(config['model_checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA1NhqNDneXq"
      },
      "outputs": [],
      "source": [
        "label_pad_token_id = -100\n",
        "data_collator = transformers.DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model = model,\n",
        "    label_pad_token_id=label_pad_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysiiSjZMQV1J"
      },
      "outputs": [],
      "source": [
        "def preprocess(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples['source'],\n",
        "        text_target=examples['target'],\n",
        "        max_length=config['max_input_length'],\n",
        "        truncation=True)\n",
        "    return model_inputs\n",
        "\n",
        "train_dataset = datasets.load_dataset(\n",
        "    'jq/salt-asr-correction', split='train[:-100]')\n",
        "train_dataset = train_dataset.shuffle()\n",
        "\n",
        "eval_dataset = datasets.load_dataset(\n",
        "    'jq/salt-asr-correction', split='train[-100:]')\n",
        "\n",
        "salt.utils.show_dataset(train_dataset, N=10)\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    preprocess,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    remove_columns=['source', 'source.language', 'target', 'target.language'])\n",
        "eval_dataset = eval_dataset.map(\n",
        "    preprocess,\n",
        "    batched=True)\n",
        "\n",
        "compute_metrics = salt.metrics.multilingual_eval_fn(\n",
        "      eval_dataset, [evaluate.load('cer')],\n",
        "      tokenizer, log_first_N_predictions=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxtsF31Yu1AR"
      },
      "outputs": [],
      "source": [
        "gen_cfg = transformers.GenerationConfig.from_pretrained(config['model_checkpoint')\n",
        "gen_cfg.max_new_tokens = config['max_output_length']\n",
        "training_settings.generation_config = gen_cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjocS5ApPr-i",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "trainer = transformers.Seq2SeqTrainer(\n",
        "  model,\n",
        "  training_settings,\n",
        "  train_dataset = train_dataset,\n",
        "  eval_dataset = eval_dataset,\n",
        "  data_collator = data_collator,\n",
        "  tokenizer = tokenizer,\n",
        "  compute_metrics = compute_metrics,\n",
        "  callbacks = [\n",
        "      salt.utils.MlflowExtendedLoggingCallback(),\n",
        "      transformers.EarlyStoppingCallback(\n",
        "          early_stopping_patience = (config\n",
        "           ['early_stopping_patience']))],\n",
        ")\n",
        "\n",
        "experiment_name = config['mlflow_experiment_name']\n",
        "\n",
        "if not mlflow.get_experiment_by_name(experiment_name):\n",
        "  mlflow.create_experiment(experiment_name)\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "with mlflow.start_run(run_name=config['mlflow_run_name'], log_system_metrics=True) as run:\n",
        "\n",
        "    mlflow.set_tag(\"developer\", os.environ['MLFLOW_TRACKING_USERNAME'])\n",
        "    mlflow.log_params(config)\n",
        "\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXpRWc71gRmA"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(config['training_args']['hub_model_id'])\n",
        "model.push_to_hub(config['training_args']['hub_model_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMjiM23_u1AT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}