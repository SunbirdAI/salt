{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAalbJhVPW2ZLa/m+BWJe0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunbirdAI/salt/blob/main/notebooks/data_preparation/pronoun_modification_for_english_targets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create English target text by converting pronouns\n",
        "\n",
        "In some local languages, gender is not specified by default in a pronoun. When translating into English, we therefore need to train the models not to invent a gender when none has been specified in the source text. This notebook creates English target text by ambiguating gender unless it can be inferred from the context."
      ],
      "metadata": {
        "id": "hSajXB_oAKVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMM04E9irb_d"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/sunbirdai/salt.git\n",
        "#!pip install -qr salt/requirements.txt\n",
        "!pip install -q openai\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import pandas as pd\n",
        "import openai\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "import multiprocessing\n",
        "import datasets\n",
        "import pydantic"
      ],
      "metadata": {
        "id": "h76bfNYErvsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "client = openai.OpenAI(\n",
        "    api_key=userdata.get('OPENAI_API_KEY'),\n",
        ")"
      ],
      "metadata": {
        "id": "6kkzPpcfhHpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper functions\n",
        "def ambiguate_gender(s):\n",
        "  '''Replace pronouns with ambiguous placeholders.'''\n",
        "\n",
        "  substitutions = {\n",
        "      'he': 'HE_SHE',\n",
        "      'she': 'HE_SHE',\n",
        "      'his': 'HIS_HER',\n",
        "      'hers': 'HIS_HERS',\n",
        "      'her': 'HIM_HER_HIS',\n",
        "      'him': 'HIM_HER',\n",
        "      'himself': 'HIMSELF_HERSELF',\n",
        "      'herself': 'HIMSELF_HERSELF',\n",
        "      'he\\'s': 'HES_SHES',\n",
        "      'she\\'s': 'HES_SHES',\n",
        "  }\n",
        "\n",
        "  for word, sub in substitutions.items():\n",
        "    s = re.sub(r'\\b'+word.lower()+r'\\b', sub, s, flags=re.IGNORECASE)\n",
        "\n",
        "  return s\n",
        "\n",
        "class TextResponse(pydantic.BaseModel):\n",
        "    text: str\n",
        "\n",
        "def modify_pronouns(text):\n",
        "  '''Given text with HE_SHE (etc) placeholders, reconstruct a sentence.\n",
        "\n",
        "  Args:\n",
        "    input: (index : int, text: str) tuple\n",
        "\n",
        "  Returns:\n",
        "    index, reconstructed_text\n",
        "  '''\n",
        "\n",
        "  instruction = (\n",
        "    \"\"\"\n",
        "**Task:** Correct the provided list of sentences by replacing placeholders\n",
        "(HE_SHE, HIS_HER, HIM_HER_HIS) with appropriate pronouns, making it readable.\n",
        "Try to infer the gender from the context, otherwise use \"he/she\", \"they\", or\n",
        "\"theirs\" as appropriate. Also clean up any formatting or spelling issues.\n",
        "\n",
        "**Examples:**\n",
        "Input: HE_SHE gave HIM_HER_HIS pen to the girl so HE_SHE could do HIS_HER homework.\n",
        "Output: He/she gave their pen to the girl so she could do her homework.\n",
        "# 'the girl' inferred as female.\n",
        "\n",
        "Input: The chairman said HE_SHE would call tomorrow.\n",
        "Output: The chairman said he would call tomorrow.\n",
        "# 'chairman' inferred as male.\n",
        "\n",
        "Input: are u with HIM_HER?\n",
        "Output: Are you with him/her?\n",
        "# gender can't be inferred here.\n",
        "\n",
        "Input: HIS_HER brother came home.\n",
        "Output: His/her brother came home.\n",
        "# gender can't be inferred here\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "  ambiguated = ambiguate_gender(text)\n",
        "\n",
        "  # There might be nothing to ambiguate.\n",
        "  if ambiguated == text:\n",
        "    return text\n",
        "\n",
        "  try:\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": instruction},\n",
        "            {\"role\": \"user\", \"content\": ambiguated},\n",
        "        ],\n",
        "        response_format=TextResponse,\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message\n",
        "\n",
        "    if response.parsed:\n",
        "      return response.parsed.text\n",
        "\n",
        "    if response.refusal:\n",
        "      print(response.refusal)\n",
        "\n",
        "    return text\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e, text)\n",
        "    return text\n",
        "\n",
        "def modify_with_index(input):\n",
        "  index, text = input\n",
        "  return index, modify_pronouns(text)"
      ],
      "metadata": {
        "id": "8Sa3ESPyfyo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modify_pronouns('She was on the way to give birth.')"
      ],
      "metadata": {
        "id": "bsPjV1N2XoE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_REPO = 'Sunbird/external-translation-datasets'\n",
        "SOURCE_CONFIG = 'mt560_ibo.parquet'\n",
        "TARGET_REPO = 'jq/external-translation-data'\n",
        "TARGET_CONFIG = 'mt560_ibo'\n",
        "SPLIT = 'train'\n",
        "\n",
        "ds = datasets.load_dataset(SOURCE_REPO, SOURCE_CONFIG)\n",
        "split = SPLIT\n",
        "df = ds[split].to_pandas()\n",
        "\n",
        "rows_to_alter = df['eng_text'].apply(ambiguate_gender) != df['eng_text']\n",
        "num_to_process = np.sum(rows_to_alter)\n",
        "print(f\"{num_to_process} of {len(df)} examples to be converted.\")"
      ],
      "metadata": {
        "id": "5LCwtYpEEP2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = list(\n",
        "    zip(range(len(df)), list(df['eng_text']))\n",
        ")\n",
        "with multiprocessing.Pool(50) as p:\n",
        "  completions = list(\n",
        "      tqdm(p.imap_unordered(modify_with_index, inputs), total=len(df)))\n",
        "\n",
        "if 'eng_target_text' in df.columns:\n",
        "  completions_ordered = list(df['eng_target_text'])\n",
        "else:\n",
        "  completions_ordered = list(df['eng_text'])\n",
        "\n",
        "for i, text in completions:\n",
        "  if text:\n",
        "    completions_ordered[i] = text\n",
        "  else:\n",
        "    print(f'Falling back to eng_text for row {i}')\n",
        "    completions_ordered[i] = df['eng_text'][i]\n",
        "\n",
        "df['eng_target_text'] = completions_ordered\n",
        "df.rename(columns={'eng_text': 'eng_source_text'}, inplace=True)"
      ],
      "metadata": {
        "id": "f7FhEz-X4-X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[rows_to_alter]"
      ],
      "metadata": {
        "id": "wNZxGYMjDS4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets.Dataset.from_pandas(df)\n",
        "ds.push_to_hub(TARGET_REPO,\n",
        "               config_name=TARGET_CONFIG,\n",
        "               private=False,\n",
        "               split=SPLIT)"
      ],
      "metadata": {
        "id": "gcHoCCRDQIAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create instruction text\n",
        "\n",
        "Use only the versions of datasets with corrected pronouns as above."
      ],
      "metadata": {
        "id": "LIAcrl2eAXMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def row_to_instruction(row):\n",
        "  return f\"\"\"Translate to English\n",
        "\n",
        "# Input\n",
        "{row['lug_text']}\n",
        "\n",
        "# Output\n",
        "{row['eng_target_text']}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mlOur83PqfnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = 'jq/external_mt_datasets_with_eng_target'\n",
        "\n",
        "# SALT dataset\n",
        "ds = datasets.load_dataset(\n",
        "    'jq/salt_with_eng_target', 'text-all', split='train')\n",
        "df = ds.to_pandas()\n",
        "examples = list(df.apply(row_to_instruction, axis=1))\n",
        "print(len(examples))\n",
        "\n",
        "# External datasets\n",
        "configs = [\n",
        "  'lafand-en-lug-combined.parquet',\n",
        "  'ai4d.parquet',\n",
        "  'bt_from-eng-google.parquet',\n",
        "  'flores200.parquet',\n",
        "  'lafand-en-lug-combined.parquet',\n",
        "  'mozilla_110.parquet',\n",
        "  'tico19.parquet',\n",
        "]\n",
        "\n",
        "for config in configs:\n",
        "  ds = datasets.load_dataset(\n",
        "      'jq/external_mt_datasets_with_eng_target', config, split='train')\n",
        "  df = ds.to_pandas()\n",
        "  examples.extend(list(df.apply(row_to_instruction, axis=1)))\n",
        "  print(len(examples))"
      ],
      "metadata": {
        "id": "8c4GedTzlnmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['instruction'] = examples"
      ],
      "metadata": {
        "id": "oaClNmZ44BGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets.Dataset.from_pandas(df)\n",
        "ds.push_to_hub(\"Sunbird/sunflower-data\", config_name='translation-to-eng-corrected', private=True, split='train')"
      ],
      "metadata": {
        "id": "NCkzOlRm4D-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "verymBJ67EDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}