{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998a753-c59b-4cb1-a7fc-1b289cc2e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q transformers\n",
    "!pip install -q librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ebdc5-42bb-44db-8919-755525f9b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "import librosa\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da33a85-5cac-4971-b949-33de8a619548",
   "metadata": {},
   "source": [
    "Get some data to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce346ee-9e34-47a6-91f5-71437b69b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = datasets.load_dataset(\"Sunbird/salt-practical-eval\", \"sema_eng\", split=\"test\")\n",
    "dataset_iterator = iter(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a73ab-f041-4cb4-b249-b5c6d7ba1568",
   "metadata": {},
   "source": [
    "Get references to the model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546acb7-e043-4355-822b-ee6d15b953dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = transformers.WhisperProcessor.from_pretrained(\n",
    "    \"jq/whisper-large-v2-multilingual-prompts-corrected\", language=None, task=\"transcribe\")\n",
    "\n",
    "model = transformers.WhisperForConditionalGeneration.from_pretrained(\n",
    "    \"jq/whisper-large-v2-multilingual-prompts-corrected\").to('cuda')\n",
    "# Note: If a pipeline is already loaded in memory, then we can just use:\n",
    "# model = whisper_pipeline.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ee72d-db8b-4ff4-96bf-2c2c84e22b11",
   "metadata": {},
   "source": [
    "Get a mapping from token IDs to language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3826389-a6ca-45f6-82c4-1d9f4389163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_whisper_language_id_tokens = {\n",
    "    'eng': 50259,\n",
    "    'ach': 50357,\n",
    "    'lgg': 50356,\n",
    "    'lug': 50355,\n",
    "    'nyn': 50354,\n",
    "    'teo': 50353,\n",
    "}\n",
    "token_to_language = {}\n",
    "for lang, token in salt_whisper_language_id_tokens.items(): \n",
    "    token_to_language[token] = lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536776a3-4c0f-4c66-bda6-86a5d970ac6c",
   "metadata": {},
   "source": [
    "Get test audio and resample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d5927-3f9b-43c6-95f8-a33ebbb416ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(dataset_iterator)\n",
    "audio = example['audio']['array']\n",
    "audio = librosa.resample(\n",
    "    audio, orig_sr=example['audio']['sampling_rate'], target_sr=16000)\n",
    "\n",
    "display.Audio(audio, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ec928-770a-4833-ab4e-42ccb520fb38",
   "metadata": {},
   "source": [
    "Run the model and pull out the language token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f0e60-2076-4463-8b36-586afb627296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The results are probably better if silences are removed.\n",
    "input_features = processor(\n",
    "    audio,\n",
    "    sampling_rate=16000,\n",
    "    return_tensors=\"pt\",\n",
    "    do_normalize=True,\n",
    "    device=\"cuda\").input_features\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(\n",
    "        input_features.to(\"cuda\"),\n",
    "        max_new_tokens=5\n",
    "    )[0]\n",
    "# Note here that we don't need all the tokens corresonding to the full\n",
    "# text: we're just interested in the language detection here. So save\n",
    "# time by quitting after detecting just a few tokens.\n",
    "\n",
    "language_token = int(predicted_ids[1])\n",
    "\n",
    "detected_language = token_to_language.get(\n",
    "    int(predicted_ids[1]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f0264-4447-47ef-9fed-98e3239ce944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Language detected: {detected_language}')\n",
    "print(processor.decode(predicted_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92dcaf-7fba-4a35-b64f-79e0a0e509d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
