{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunbirdAI/salt/blob/main/notebooks/sample_asr_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sunbird ASR evaluation"
      ],
      "metadata": {
        "id": "pld_rq1XtZbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run ASR eval for SB and other models on our partner datasets\n",
        "#\n",
        "# Notebook location:\n",
        "# 'Shared drives/Sunbird AI/Projects/African Language Technology/ASR Evaluation'\n",
        "#\n",
        "# Ideally we should move all the eval data once its stable to\n",
        "# SB huggingface and call it from there.\n",
        "#\n",
        "# Goal is to link the notebook to a leaderboard, where results are\n",
        "# automatically updated for the different models as a way of tracking\n",
        "# model improvements."
      ],
      "metadata": {
        "id": "CtP7J_CNuTw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDEFy_3U0OB3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install evaluate jiwer\n",
        "!pip install pyctcdecode\n",
        "!pip install kenlm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import stuff\n",
        "\n",
        "import os\n",
        "import json\n",
        "import string\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import Dataset, Audio\n",
        "from evaluate import load\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "from transformers import (\n",
        "    Wav2Vec2ForCTC,\n",
        "    Wav2Vec2CTCTokenizer,\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2Processor,\n",
        "    Wav2Vec2ProcessorWithLM,\n",
        "    AutomaticSpeechRecognitionPipeline,\n",
        "    AutoProcessor,\n",
        ")\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "from transformers import pipeline\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "ThhtZdrE00cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/gdrive')\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "U9tb5HHX0_Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch eval data\n",
        "Currently data is fetched from Google Drive. Once the data is stable, data can be moved to SB huggingface and fetched directly."
      ],
      "metadata": {
        "id": "sLT3on6TwcQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_ucfd_eng.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_ucfd_lug.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_sema_eng.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_sema_lug.zip >> /dev/null\n",
        "!unzip /gdrive/'Shared drives'/'Sunbird AI'/Projects/'African Language Technology'/'ASR Evaluation'/eval_trac_fm_lug.zip >> /dev/null"
      ],
      "metadata": {
        "id": "5z7T7I851HvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load eval data\n",
        "\n",
        "def load_eval_data(folder_path):\n",
        "  # Load eval dataset\n",
        "  csv_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.csv')]\n",
        "\n",
        "  if not csv_files:\n",
        "      raise FileNotFoundError(\"No CSV file found in the folder.\")\n",
        "\n",
        "  csv_file_path = os.path.join(folder_path, csv_files[0])\n",
        "\n",
        "  df = pd.read_csv(csv_file_path)\n",
        "\n",
        "  # Check if 'filename' column exists in the CSV file\n",
        "  if 'filename' not in df.columns:\n",
        "      raise ValueError(\"'filename' column not found in the CSV file.\")\n",
        "\n",
        "  # Add the folder path to each entry in the 'filename' column\n",
        "  df['filename'] = df['filename'].apply(lambda x: os.path.join(folder_path, x))\n",
        "\n",
        "  eval_data = Dataset.from_dict(\n",
        "  {'audio': df.filename.to_list(), 'transcription': df.transcription.to_list()}\n",
        "  ).cast_column('audio', Audio())\n",
        "\n",
        "  return eval_data\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ir8HOqE0xZIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ucfd_eng_eval_data = load_eval_data('eval_ucfd_eng')\n",
        "ucfd_lug_eval_data = load_eval_data('eval_ucfd_lug')\n",
        "sema_eng_eval_data = load_eval_data('eval_sema_eng')\n",
        "sema_lug_eval_data = load_eval_data('eval_sema_lug')\n",
        "trac_fm_lug_eval_data = load_eval_data('eval_trac_fm_lug')"
      ],
      "metadata": {
        "id": "67D3VlSB1tGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sema_eng_eval_data"
      ],
      "metadata": {
        "id": "ITILy0Oo9kHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Models\n",
        "\n",
        "def wav2vecpipeline(model_id, lang, lm_file, device=device, use_lm=True):\n",
        "  # Get Wav2Vec2ForCTC model based transformer pipeline\n",
        "  model = Wav2Vec2ForCTC.from_pretrained(model_id).to(device)\n",
        "\n",
        "  # Processor setup\n",
        "  processor = AutoProcessor.from_pretrained(model_id)\n",
        "  tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_id)\n",
        "\n",
        "  tokenizer.set_target_lang(lang)\n",
        "  model.load_adapter(lang)\n",
        "\n",
        "\n",
        "  # Feature extractor setup\n",
        "  feature_extractor = Wav2Vec2FeatureExtractor(\n",
        "      feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True\n",
        "  )\n",
        "  processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "  vocab_dict = processor.tokenizer.get_vocab()\n",
        "  sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
        "\n",
        "  if use_lm:\n",
        "\n",
        "    # Language model file setup\n",
        "    lm_file_name = lm_file\n",
        "    lm_file_subfolder = \"language_model\"\n",
        "    lm_file = hf_hub_download(\n",
        "        repo_id=model_id,\n",
        "        filename=lm_file_name,\n",
        "        subfolder=lm_file_subfolder,\n",
        "    )\n",
        "\n",
        "    # Decoder setup -> Use KenLM as decoder\n",
        "    decoder = build_ctcdecoder(\n",
        "        labels=list(sorted_vocab_dict.keys()),\n",
        "        kenlm_model_path=lm_file,\n",
        "    )\n",
        "\n",
        "    # Use the lm as the Processor\n",
        "    processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "        feature_extractor=feature_extractor,\n",
        "        tokenizer=tokenizer,\n",
        "        decoder=decoder,\n",
        "    )\n",
        "    feature_extractor._set_processor_class(\"Wav2Vec2ProcessorWithLM\")\n",
        "\n",
        "    # ASR Pipeline, with a chunk and stride --> Make it work for even super long audio\n",
        "    pipe = AutomaticSpeechRecognitionPipeline(\n",
        "        model=model,\n",
        "        tokenizer=processor_with_lm.tokenizer,\n",
        "        feature_extractor=processor_with_lm.feature_extractor,\n",
        "        decoder=processor_with_lm.decoder,\n",
        "        device=device,\n",
        "        chunk_length_s=10,\n",
        "        stride_length_s=(4, 2),\n",
        "        return_timestamps=\"word\"\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    pipe = AutomaticSpeechRecognitionPipeline(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        feature_extractor=feature_extractor,\n",
        "        decoder=processor.decode,\n",
        "        device=device,\n",
        "        chunk_length_s=10,\n",
        "        stride_length_s=(4, 2),\n",
        "        return_timestamps=\"word\"\n",
        "    )\n",
        "\n",
        "  return pipe"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tp4mvljU4JUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisperbase = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"openai/whisper-base\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "facebookmms = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"facebook/mms-1b-all\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "whisperSBFinetuned = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model = \"akera/whisper-base-sb-english\",\n",
        "    device = device\n",
        ")\n",
        "\n",
        "sunbirdmms = wav2vecpipeline(\n",
        "    model_id = \"Sunbird/sunbird-mms\",\n",
        "    lang = \"eng\",\n",
        "    lm_file = \"eng_5gram.bin\",\n",
        "    device = device,\n",
        "    use_lm = True,\n",
        ")\n",
        "\n",
        "facebooklugmms = wav2vecpipeline(\n",
        "    model_id = \"facebook/mms-1b-all\",\n",
        "    lang = \"lug\",\n",
        "    lm_file = \"lug_eng_5gram.bin\",\n",
        "    device = device,\n",
        "    use_lm = False\n",
        ")"
      ],
      "metadata": {
        "id": "N6IdhCg22ay-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions\n",
        "\n",
        "def get_predictions(pipeline, eval_datasets):\n",
        "  eval_predictions = {}\n",
        "  for eval_name, eval_data in eval_datasets.items():\n",
        "    predictions = []\n",
        "    for prediction in pipeline(eval_data['audio']):\n",
        "      predictions.append(prediction['text'])\n",
        "    eval_predictions[eval_name] = predictions\n",
        "  return eval_predictions"
      ],
      "metadata": {
        "id": "KDbfZFIu_UbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_eval_datasets = {\n",
        "    \"ucfd_eng\": ucfd_eng_eval_data,\n",
        "    \"sema_eng\": sema_eng_eval_data,\n",
        "}\n",
        "\n",
        "lug_eval_datasets = {\n",
        "    \"ucfd_lug\": ucfd_lug_eval_data,\n",
        "    \"sema_lug\": sema_lug_eval_data,\n",
        "    \"trac_fm_lug\": trac_fm_lug_eval_data\n",
        "}"
      ],
      "metadata": {
        "id": "4y8UIX3DA9ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eng eval\n",
        "whisperbasepredictions = get_predictions(whisperbase, eng_eval_datasets)\n",
        "facebookmmspredictions = get_predictions(facebookmms, eng_eval_datasets)\n",
        "sunbirdmmspredictions = get_predictions(sunbirdmms, eng_eval_datasets)\n",
        "whispersbfinetunedpredictions = get_predictions(whisperSBFinetuned, eng_eval_datasets)"
      ],
      "metadata": {
        "id": "AAR8rNKOBT1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lug eval\n",
        "facebooklugmmspredictions = get_predictions(facebooklugmms, lug_eval_datasets)"
      ],
      "metadata": {
        "id": "mWLmSSAaCZhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate WER\n",
        "\n",
        "def lower_case_and_strip_punctuation(string_list, allowed_punctuation=\"'\"):\n",
        "  '''Convert a list of strings by converting to lower case and removing\n",
        "  punctuation. This helps when calculating WER, as we're interested in which\n",
        "  words were predicted more than the capitalisation or punctuation.'''\n",
        "  result = []\n",
        "  for s in string_list:\n",
        "    s = s.lower()\n",
        "    punct = list(string.punctuation)\n",
        "    if allowed_punctuation:\n",
        "        for allowed in allowed_punctuation:\n",
        "            punct.remove(allowed)\n",
        "    result.append(''.join([c for c in s if c not in punct]))\n",
        "  return result\n",
        "\n",
        "def get_wer(predictions, datasets):\n",
        "  wer_metric = load(\"wer\")\n",
        "  output_wer = {}\n",
        "  for eval_name, eval_data in datasets.items():\n",
        "    wer = 100 * wer_metric.compute(\n",
        "        references=lower_case_and_strip_punctuation(eval_data[\"transcription\"]),\n",
        "        predictions=lower_case_and_strip_punctuation(predictions[eval_name]),\n",
        "    )\n",
        "    output_wer[eval_name] = round(wer, 2)\n",
        "  return output_wer\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZsRoczZXDhLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer_whisperbase = get_wer(whisperbasepredictions, eng_eval_datasets)\n",
        "wer_facebookmms = get_wer(facebookmmspredictions, eng_eval_datasets)\n",
        "wer_sunbirdmms = get_wer(sunbirdmmspredictions, eng_eval_datasets)\n",
        "wer_whisperSBFinetuned = get_wer(whispersbfinetunedpredictions, eng_eval_datasets)\n",
        "wer_facebooklugmms = get_wer(facebooklugmmspredictions, lug_eval_datasets)"
      ],
      "metadata": {
        "id": "Elwx1K3fEDjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Whisperbase WER: {json.dumps(wer_whisperbase, indent=4)}\")\n",
        "print(f\"FacebookMMS WER: {json.dumps(wer_facebookmms, indent=4)}\")\n",
        "print(f\"SunbirdMMS WER: {json.dumps(wer_sunbirdmms, indent=4)}\")\n",
        "print(f\"SWhisperSBFinetuned WER: {json.dumps(wer_whisperSBFinetuned, indent=4)}\")\n",
        "print(f\"FacebookLugMMS WER: {json.dumps(wer_facebooklugmms, indent=4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1SOQUnpuGm0",
        "outputId": "690a7430-4c25-481b-be5f-9c6b8f1fbc65"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisperbase WER: {\n",
            "    \"ucfd_eng\": 65.1,\n",
            "    \"sema_eng\": 85.31\n",
            "}\n",
            "FacebookMMS WER: {\n",
            "    \"ucfd_eng\": 90.25,\n",
            "    \"sema_eng\": 80.81\n",
            "}\n",
            "SunbirdMMS WER: {\n",
            "    \"ucfd_eng\": 53.32,\n",
            "    \"sema_eng\": 50.47\n",
            "}\n",
            "SWhisperSBFinetuned WER: {\n",
            "    \"ucfd_eng\": 46.6,\n",
            "    \"sema_eng\": 47.16\n",
            "}\n",
            "FacebookLugMMS WER: {\n",
            "    \"ucfd_lug\": 84.8,\n",
            "    \"sema_lug\": 87.86,\n",
            "    \"trac_fm_lug\": 63.22\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions(predictions1, predictions2, predictions3, predictions4, ground_truths):\n",
        "    for idx, (pred1, pred2, pred3, pred4, truth) in enumerate(zip(predictions1, predictions2, predictions3, predictions4, ground_truths)):\n",
        "        print(f\"Example {idx + 1}:\")\n",
        "        print(f\"  Ground Truth: {truth}\")\n",
        "        print(f\"  Wspr-FineTuned: {pred1}\")\n",
        "        print(f\"  SB-MMS: {pred2}\")\n",
        "        print(f\"  Wspr-Base: {pred3}\")\n",
        "        print(f\"  FacebookMMS: {pred4}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "ds = 'trac_fm_lug'\n",
        "\n",
        "if ds != 'trac_fm_lug':\n",
        "    whispersbfinetunedpredictions = whispersbfinetunedpredictions[ds]\n",
        "    sunbirdmmspredictions = sunbirdmmspredictions[ds]\n",
        "    whisperbasepredictions = whisperbasepredictions[ds]\n",
        "    facebookmmspredictions = facebookmmspredictions[ds]\n",
        "    ground_truths = eng_eval_datasets[ds][\"transcription\"]\n",
        "\n",
        "    compare_predictions(whispersbfinetunedpredictions, sunbirdmmspredictions, whisperbasepredictions, facebookmmspredictions, ground_truths)\n",
        "else:\n",
        "    predictions = facebooklugmmspredictions[ds]\n",
        "    ground_truths = lug_eval_datasets[ds][\"transcription\"]\n",
        "    for idx, pred in enumerate(zip(predictions, ground_truths)):\n",
        "        print(f\"Example {idx + 1}:\")\n",
        "        print(f\"  Ground Truth: {ground_truths[idx]}\")\n",
        "        print(f\"  FacebookLugMMS: {pred[0]}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "-NPxBNIefz95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2B5RrtvINSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}